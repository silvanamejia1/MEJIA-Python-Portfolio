{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tb1XXLp22Mj1hPgwRFvXKB6TP029eTRn","timestamp":1710975157382}],"mount_file_id":"1tb1XXLp22Mj1hPgwRFvXKB6TP029eTRn","authorship_tag":"ABX9TyN/mfEDNxWG52+0cwSy7tb2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Scripts\n","\n","`clean_data.py`: This Python file contains all the functions used to clean the geographic fields, the race and ethnicity columns, and action taken columns, among others. It also finds and flags co-applicants among five different fields.\n","\n","`categorize_data.py`: This Python file contains all the functions that standardize the columns that are used in the regression, including debt-to-income ratio, combined loan-to-value ratio, among others.\n","\n","`use_regression.py`: This Python file contains all the functions needed to run the regression and other statistical tests.\n","\n","[Download from GitHub](https://github.com/the-markup/investigation-redlining/tree/main/utils). Code to download in your notebook is included below."],"metadata":{"id":"6hqpPWzSUo9w"}},{"cell_type":"code","source":["# code to download the file within your Python IDE\n","import json, requests, urllib, urllib.request\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/utils/categorize_data.py\", \"categorize_data.py\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/utils/clean_data.py\", \"clean_data.py\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/utils/use_regression.py\", \"use_regression.py\")"],"metadata":{"id":"HJ47HXUvVp-d","executionInfo":{"status":"ok","timestamp":1711030570262,"user_tz":240,"elapsed":833,"user":{"displayName":"Katherine Walden","userId":"17094108395123900917"}},"outputId":"8a06a6f2-2135-4cd4-84e6-60c8563441a1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('use_regression.py', <http.client.HTTPMessage at 0x7f0ecc2560b0>)"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["from categorize_data import *\n","from clean_data import *\n","from use_regression import *"],"metadata":{"id":"9IiDa3HJeP6B","executionInfo":{"status":"ok","timestamp":1711030574265,"user_tz":240,"elapsed":2355,"user":{"displayName":"Katherine Walden","userId":"17094108395123900917"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"iX9wmQmkEnYS"}},{"cell_type":"markdown","source":["## Census Data\n","\n","`counties`\n","- We used 2019 American Community Survey data for the property values for each county in the country––table B25077. We downloaded the data from the Census and included the raw dataset.\n","\n","`metro`\n","- We used 2019 American Community Survey data for the metro area populations, which we downloaded from the Census website and acquired through the Census API.\n","\n","`demo`\n","- We used a Census dataset that lists all counties in the country and the respective metro area that they belong to. That raw dataset is included here. We used this dataset to map counties in HMDA data to their respective metro areas while incorporating the population categories for each metro area.\n"],"metadata":{"id":"kPjiXoEwid5k"}},{"cell_type":"code","source":["import pandas as pd\n","counties = pd.read_csv(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/data/census_data/county_to_metro_crosswalk/clean/all_counties_210804.csv\")\n","metro = pd.read_csv(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/data/census_data/metro_area_pop/raw/metro_division_pop2019.csv\")\n","propValue = pd.read_csv(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/data/census_data/property_values/ACSDT5Y2019.B25077_data_with_overlays_2021-06-23T115616.csv\")\n","demo = pd.read_csv(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/data/census_data/racial_ethnic_demographics/clean/tract_race_pct2019_210204.csv\")"],"metadata":{"id":"21KPCOn3lTNU","executionInfo":{"status":"ok","timestamp":1711030596145,"user_tz":240,"elapsed":2074,"user":{"displayName":"Katherine Walden","userId":"17094108395123900917"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## CFPB Data\n","\n","Original 2019 HDMA source data from the [CFPB website](https://ffiec.cfpb.gov/data-publication/dynamic-national-loan-level-dataset/2019).\n","- [Data dictionary](https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/public-lar-schema)\n","- [Other field-level documentation](https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields)\n","\n","The raw data here is over `6 GB`. We'll work with the output of the reporting team's filtering/reshaping. The broad strokes of their workflow....\n","- Standardize data\n","- Standardize applicant and co-applicant race/ethnicity\n","- Standardize credit models\n","- Standardize co-applicant info\n","- Standardize outcomes\n","- Connect lender info to mortgage info\n","\n","To unpack the full data processing workflow:\n","- [Reporting team's Jupyter Notebook](https://github.com/the-markup/investigation-redlining/blob/main/notebooks/process/1_clean_data.ipynb)\n","- [Prof. Walden's version of their notebook](https://colab.research.google.com/drive/1406la8gg4v7u8LBstU9Ec1GQrKVNe1Da?usp=sharing)"],"metadata":{"id":"_gXoiS74YzFF"}},{"cell_type":"code","source":["import pandas as pd # import\n","hmda19_df2 = pd.read_csv(\"output.csv\", dtype=str) # load data\n","hmda19_df2 # inspect data"],"metadata":{"id":"J7NnAkMBY2WO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hmda19_df2.info() # inspect data"],"metadata":{"id":"4B9a3482ZH3q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Lender Data\n","\n","The reporting team also used an `lei` lookup table with additional info on the lenders.\n","- [Link to this data](https://ffiec.cfpb.gov/data-publication/snapshot-national-loan-level-dataset/2019)"],"metadata":{"id":"N4yyhWqfhFz7"}},{"cell_type":"code","source":["lenders = pd.read_csv(\"https://raw.githubusercontent.com/the-markup/investigation-redlining/main/data/supplemental_hmda_data/cleaned/lender_definitions_em210513.csv\")\n","lenders # inspect output"],"metadata":{"id":"_OaCeZzVhOvw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Cleaning"],"metadata":{"id":"ysJ0auOnchDp"}},{"cell_type":"markdown","source":["## 1- Merge Lender Info"],"metadata":{"id":"BY-31Z_bkkjj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"behavioral-vietnam"},"outputs":[],"source":["lender_def2 = lenders[['lei', 'lar_count', 'assets', 'lender_def', 'con_apps']].copy()\n","lender_def2.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"incident-kenya"},"outputs":[],"source":["hmda19_df2Merged = pd.merge(hmda19_df2, lender_def2, how = 'left', on='lei')\n","hmda19_df2Merged"]},{"cell_type":"markdown","metadata":{"id":"static-athens"},"source":["Every record in HMDA data has a lender match. There are no missing values after the join."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lucky-designation"},"outputs":[],"source":["hmda19_df2Merged['lar_count'].isnull().values.sum()"]},{"cell_type":"markdown","metadata":{"id":"located-milan"},"source":["Only 30,000 records, less than one percent,  in overall HMDA data come from no definitions for lenders.\n","- 1: Banks\n","- 2: Credit Union\n","- 3: Independent Mortgage Companies\n","- 4: No definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"young-saint"},"outputs":[],"source":["print(hmda19_df2Merged['lender_def'].value_counts(dropna = False, normalize = True) * 100)"]},{"cell_type":"markdown","source":["## 2- Add Metro Definitions"],"metadata":{"id":"pQlswoBvlLNA"}},{"cell_type":"code","source":["counties.info() # inspect counties df"],"metadata":{"id":"amaZ8h8xl-Bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"assured-marijuana"},"outputs":[],"source":["counties2 = counties[['fips_state_code', 'fips_county_code', 'metro_code', 'metro_type_def',\n","                            'metro_percentile']].copy()\n","\n","counties2 = counties2.rename(columns = {'fips_state_code': 'state_fips',\n","                                              'fips_county_code': 'county_fips'})\n","\n","counties2.head(1)"]},{"cell_type":"markdown","source":["Majority of applications come from metros in the 80th percentile or larger ones.\n","\n","- 111: Micro\n","- 000: No Metro\n","- 99: 99th percentile\n","- 9: 90th percentile"],"metadata":{"id":"I6R6mWggmHov"}},{"cell_type":"code","source":["hmda19_df2Merged.info()"],"metadata":{"id":"I9jzZQrk-gB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counties2 = counties2.astype({'state_fips':str, 'county_fips':str}) # convert data type for merge\n","counties2.info()"],"metadata":{"id":"Dy4uDzJx-jMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crazy-compromise"},"outputs":[],"source":["hmda19_df2Merged2 = pd.merge(hmda19_df2Merged, counties2, how = 'left', on = ['state_fips', 'county_fips'])\n","\n","hmda19_df2Merged2['metro_percentile'].value_counts(dropna = False, normalize = True) * 100"]},{"cell_type":"markdown","source":["## 3-Add Property Value By County"],"metadata":{"id":"MIBnjfq4_N-9"}},{"cell_type":"code","source":["propValue.info() # inspect property value info"],"metadata":{"id":"560I2TMq_PTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"changing-shoot"},"outputs":[],"source":["prop_values_df2 = propValue[(propValue['GEO_ID'] != 'id')]\n","\n","prop_values_df3 = prop_values_df2.rename(columns = {'B25077_001E': 'median_value',\n","                                                    'B25077_001M': 'median_value_moe'})\n","\n","prop_values_df3['state_fips'] = prop_values_df3['GEO_ID'].str[9:11]\n","prop_values_df3['county_fips'] = prop_values_df3['GEO_ID'].str[11:]\n","\n","prop_values_df4 = prop_values_df3[['state_fips', 'county_fips', 'median_value']].copy()\n","\n","\n","prop_values_df4.info()"]},{"cell_type":"markdown","metadata":{"id":"domestic-bradley"},"source":["Convert property value to numeric\n","- No property value for these two counties"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"romance-revelation"},"outputs":[],"source":["prop_values_df4[(prop_values_df4['median_value'] == '-')]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"threatened-mixer"},"outputs":[],"source":["prop_values_df4.loc[(prop_values_df4['median_value'] != '-'), 'median_prop_value'] = prop_values_df4['median_value']\n","prop_values_df4.loc[(prop_values_df4['median_value'] == '-'), 'median_prop_value'] = np.nan\n","prop_values_df4['median_prop_value'] = pd.to_numeric(prop_values_df4['median_prop_value'])\n","\n","prop_values_df4[(prop_values_df4['median_prop_value'].isnull())]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"classical-ultimate"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, prop_values_df4, how = 'left', on = ['state_fips', 'county_fips'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"colonial-indian"},"outputs":[],"source":["hmda19_df2.loc[(hmda19_df2['property_value'] != 'Exempt'), 'prop_value'] = hmda19_df2['property_value']\n","\n","hmda19_df2.loc[(hmda19_df2['property_value'] == 'Exempt'), 'prop_value'] = np.nan\n","\n","hmda19_df2['prop_value'] = pd.to_numeric(hmda19_df2['prop_value'])"]},{"cell_type":"markdown","source":["## 4-Race & Ethnicity By Census Tract"],"metadata":{"id":"Jod4LwDr_uY1"}},{"cell_type":"code","source":["demo.info() # inspect df"],"metadata":{"id":"ticdAHZ__xDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fundamental-chair"},"outputs":[],"source":["demo['white_pct'] = pd.to_numeric(demo['white_pct'])\n","\n","demo['census_tract'] = demo['state'] + demo['county'] + demo['tract']\n","\n","demo2 = demo[['census_tract', 'total_estimate', 'white_pct', 'black_pct', 'native_pct', 'latino_pct',\n","                    'asian_pct', 'pacislander_pct', 'othercb_pct', 'asiancb_pct']].copy()\n","\n","demo2.sample(2, random_state = 303)"]},{"cell_type":"markdown","source":["White gradiant"],"metadata":{"id":"E1MzpeHP_8u9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"identified-blues"},"outputs":[],"source":["demo2.loc[(demo2['white_pct'] > 75), 'diverse_def'] = '1'\n","\n","demo2.loc[(demo2['white_pct'] <= 75) & (demo2['white_pct'] > 50), 'diverse_def'] = '2'\n","\n","demo2.loc[(demo2['white_pct'] <= 50) & (demo2['white_pct'] > 25), 'diverse_def'] = '3'\n","\n","demo2.loc[(demo2['white_pct'] <= 25), 'diverse_def'] = '4'\n","\n","demo2.loc[(demo2['white_pct'].isnull()), 'diverse_def'] = '5'\n","\n","demo2['diverse_def'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"brilliant-anthropology"},"source":["- 0: No census data there\n","- NaN: Records that don't find a match in the census data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"powered-fleece"},"outputs":[],"source":["demo2 = demo2.astype({'census_tract':str})\n","hmda19_df2 = pd.merge(hmda19_df2, demo2, how = 'left', on = ['census_tract'])"]},{"cell_type":"markdown","metadata":{"id":"choice-qatar"},"source":["Convert the NaN to 0's"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"secret-authentication"},"outputs":[],"source":["hmda19_df2.loc[(hmda19_df2['diverse_def'].isnull()), 'diverse_def'] = '0'\n","\n","hmda19_df2['diverse_def'].value_counts(dropna = False)"]},{"cell_type":"markdown","source":["## 5-Debt to Income Ratio"],"metadata":{"id":"2ttcSiw0Ajd9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sustained-residence"},"outputs":[],"source":["dti_df = pd.DataFrame(hmda19_df2['debt_to_income_ratio'].value_counts(dropna = False)).reset_index().\\\n","         rename(columns = {'index': 'debt_to_income_ratio', 'debt_to_income_ratio': 'count'})\n","\n","### Convert the nulls for cleaning purposes\n","dti_df = dti_df.fillna('null')\n","\n","dti_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"narrow-banana"},"outputs":[],"source":["### Running function to organize debt-to-income ratio\n","dti_df['dti_cat'] = dti_df.apply(setup_dti_cat, axis = 1)\n","\n","dti_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sudden-crossing"},"outputs":[],"source":["### Drop count column and replace the null values back to NaN\n","dti_df2 = dti_df.drop(columns = ['count'], axis = 1)\n","dti_df2 = dti_df2.replace('null', np.nan)\n","\n","dti_df2.head(2)"]},{"cell_type":"markdown","metadata":{"id":"forward-moses"},"source":["A third of entire dataset is null, when it comes to DTI ratio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stopped-worthy"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, dti_df2, how = 'left', on = ['debt_to_income_ratio'])\n","\n","hmda19_df2['dti_cat'].value_counts(dropna = False, normalize = True) * 100"]},{"cell_type":"markdown","source":["## 6-Loan-to-value ratio"],"metadata":{"id":"7Oo4SpP1Aw-E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"protected-collins"},"outputs":[],"source":["cltv_df = pd.DataFrame(hmda19_df2['combined_loan_to_value_ratio'].value_counts(dropna = False)).reset_index().\\\n","          rename(columns = {'index': 'combined_loan_to_value_ratio', 'combined_loan_to_value_ratio': 'count'})\n","\n","### Convert cltv to numeric\n","cltv_df.loc[(cltv_df['combined_loan_to_value_ratio'] != 'Exempt'), 'cltv_ratio'] =\\\n","            cltv_df['combined_loan_to_value_ratio']\n","\n","cltv_df['cltv_ratio'] = pd.to_numeric(cltv_df['cltv_ratio'])"]},{"cell_type":"markdown","metadata":{"id":"voluntary-cycle"},"source":["Downpayment Flag\n","- 1: 20 percent or more downpayment\n","- 2: Less than 20 percent\n","- 3: Nulls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"minimal-consciousness"},"outputs":[],"source":["cltv_df['downpayment_flag'] = cltv_df.apply(categorize_cltv, axis = 1)\n","cltv_df2 = cltv_df.drop(columns = ['count', 'cltv_ratio'], axis = 1)\n","\n","\n","hmda19_df2 = pd.merge(hmda19_df2, cltv_df2, how = 'left', on = ['combined_loan_to_value_ratio'])\n","hmda19_df2['downpayment_flag'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"universal-provider"},"source":["## 7-Property Value Ratio Z-Score\n","\n","Property value ratios are more normally distributed than raw property values. Because there's they are normally distributed below the 10th ratio, I will use the z-scores and place them into buckets based on those z-scores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"purple-stevens"},"outputs":[],"source":["property_value_df = pd.DataFrame(hmda19_df2.groupby(by = ['state_fips', 'county_fips', 'property_value',\n","                    'prop_value', 'median_prop_value'], dropna = False).size()).reset_index().\\\n","                     rename(columns = {0: 'count'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"manual-milan"},"outputs":[],"source":["property_value_df['property_value_ratio'] = property_value_df['prop_value'].\\\n","                                            div(property_value_df['median_prop_value']).round(3)\n","\n","property_value_df['prop_zscore'] = property_value_df.apply(calculate_prop_zscore, axis = 1).round(3)\n","\n","property_value_df['prop_value_cat'] = property_value_df.apply(categorize_property_value_ratio, axis = 1)\n","\n","property_value_df.sample(3, random_state = 303)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dressed-compression"},"outputs":[],"source":["property_value_df2 = property_value_df[['state_fips', 'county_fips', 'property_value',\n","                                        'median_prop_value', 'property_value_ratio', 'prop_zscore',\n","                                        'prop_value_cat']].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"broadband-slide"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, property_value_df2, how = 'left', on = ['state_fips', 'county_fips',\n","                     'property_value', 'median_prop_value'])"]},{"cell_type":"markdown","metadata":{"id":"binding-nitrogen"},"source":["## 8-Applicant Age\n","\n","- [9999](https://s3.amazonaws.com/cfpb-hmda-public/prod/help/2018-public-LAR-code-sheet.pdf): No Co-applicant\n","- 8888: Not Applicable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"solved-textbook"},"outputs":[],"source":["age_df = pd.DataFrame(hmda19_df2['applicant_age'].value_counts(dropna = False)).reset_index().\\\n","         rename(columns = {'index': 'applicant_age', 'applicant_age': 'count'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"individual-worthy"},"outputs":[],"source":["age_df['applicant_age_cat'] = age_df.apply(categorize_age, axis = 1)\n","\n","age_df = age_df.drop(columns = ['count'], axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"adult-africa"},"source":["#### Age Categories\n","- 1: Less than 25\n","- 2: 25 through 34\n","- 3: 35 through 44\n","- 4: 45 through 54\n","- 5: 55 through 64\n","- 6: 65 through 74\n","- 7: Greater than 74\n","- 8: Not Applicable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"placed-exploration"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, age_df, how = 'left', on = ['applicant_age'])\n","\n","hmda19_df2['applicant_age_cat'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"better-accordance"},"source":["## 9-Income and Loan Amount Log"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"electronic-jungle"},"outputs":[],"source":["hmda19_df2['income'] = pd.to_numeric(hmda19_df2['income'])\n","hmda19_df2['loan_amount'] = pd.to_numeric(hmda19_df2['loan_amount'])\n","\n","hmda19_df2['income_log'] = np.log(hmda19_df2['income'])\n","hmda19_df2['loan_log'] = np.log(hmda19_df2['loan_amount'])"]},{"cell_type":"markdown","metadata":{"id":"romance-depression"},"source":["## 10-Applicant Sex\n","- 1: Male\n","- 2: Female\n","- 3: Information not provided\n","- 4: Not Applicable\n","- 5: No Co-Applicable\n","- 6: Marked Both"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faced-dryer"},"outputs":[],"source":["sex_df = pd.DataFrame(hmda19_df2['applicant_sex'].value_counts(dropna = False)).reset_index().\\\n","         rename(columns = {'index': 'applicant_sex', 'applicant_sex': 'count'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"accomplished-worst"},"outputs":[],"source":["sex_df = sex_df.drop(columns = ['count'], axis = 1)\n","\n","sex_df['applicant_sex_cat'] = sex_df.apply(categorize_sex, axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"broadband-cattle"},"source":["#### New applicant sex categories\n","- 1: Male\n","- 2: Female\n","- 3: Not applicable\n","- 4: Makred both sexes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"logical-ireland"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, sex_df, how = 'left', on = ['applicant_sex'])\n","\n","hmda19_df2['applicant_sex_cat'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"heard-steam"},"source":["## 11-Automated Underwiting systems\n","- 1: Only one AUS was used\n","- 2: Same AUS was multiple times\n","- 3: Different AUS were used\n","- 4: Exempt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"editorial-packaging"},"outputs":[],"source":["hmda19_df2['aus_cat'].value_counts(dropna = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"convinced-capture"},"outputs":[],"source":["underwriter_df = pd.DataFrame(hmda19_df2.groupby(by = ['aus_1', 'aus_cat']).size()).reset_index().\\\n","                 rename(columns = {0: 'count'})\n","\n","underwriter_df['main_aus'] = underwriter_df.apply(categorize_underwriter, axis = 1)\n","\n","underwriter_df = underwriter_df.drop(columns = ['count'], axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"headed-consistency"},"source":["#### Main Aus\n","- 1: Desktop Underwriter\n","- 2: Loan Prospector\n","- 3: Technology Open to Approved Lenders\n","- 4: Guaranteed Underwriting System\n","- 5: Other\n","- 6: No main Aus\n","- 7: Not Applicable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aquatic-recall"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, underwriter_df, how = 'left', on = ['aus_1', 'aus_cat'])\n","\n","hmda19_df2['main_aus'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"wrapped-hungary"},"source":["## 12- Loan Term"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"generic-assistant"},"outputs":[],"source":["loanterm_df = pd.DataFrame(hmda19_df2['loan_term'].value_counts(dropna = False)).reset_index().\\\n","              rename(columns = {'index': 'loan_term', 'loan_term': 'count'})\n","\n","loanterm_df.loc[(loanterm_df['loan_term'] != 'Exempt'), 'em_loan_term'] = loanterm_df['loan_term']\n","\n","loanterm_df['em_loan_term'] = pd.to_numeric(loanterm_df['em_loan_term'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whole-arnold"},"outputs":[],"source":["loanterm_df['mortgage_term'] = loanterm_df.apply(categorize_loan_term, axis = 1)\n","\n","loanterm_df = loanterm_df.drop(columns = ['count', 'em_loan_term'])"]},{"cell_type":"markdown","metadata":{"id":"federal-springfield"},"source":["#### Mortgage Term\n","- 1: 30 year mortgage\n","- 2: Less than 30 years\n","- 3: More than 30 years\n","- 4: Not applicable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ancient-romance"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, loanterm_df, how = 'left', on = ['loan_term'])\n","\n","hmda19_df2['mortgage_term'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"impaired-bubble"},"source":["## 13-Tract MSA Income Percentage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neutral-rotation"},"outputs":[],"source":["tractmsa_income_df = pd.DataFrame(hmda19_df2['tract_to_msa_income_percentage'].value_counts(dropna = False)).\\\n","                     reset_index().rename(columns = {'index': 'tract_to_msa_income_percentage',\n","                                                     'tract_to_msa_income_percentage': 'count'})\n","\n","tractmsa_income_df['tract_msa_ratio'] = pd.to_numeric(tractmsa_income_df['tract_to_msa_income_percentage'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"accessible-organization"},"outputs":[],"source":["tractmsa_income_df['lmi_def'] = tractmsa_income_df.apply(categorize_lmi, axis = 1)\n","\n","tractmsa_income_df = tractmsa_income_df.drop(columns = ['count', 'tract_msa_ratio'], axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"complete-sixth"},"source":["LMI Definition\n","- 1: Low\n","- 2: Moderate\n","- 3: Middle\n","- 4: Upper\n","- 5: None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"horizontal-compiler"},"outputs":[],"source":["hmda19_df2 = pd.merge(hmda19_df2, tractmsa_income_df, how = 'left', on = ['tract_to_msa_income_percentage'])\n","\n","hmda19_df2['lmi_def'].value_counts(dropna = False)"]},{"cell_type":"markdown","metadata":{"id":"remarkable-desert"},"source":["## 14-Filter:\n","\n","#### For Conventional and FHA loans that first-lien, one-to-four unit, site built unites for home purchase where the applicant is going to live in that property"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"public-surge"},"outputs":[],"source":["one_to_four = ['1', '2', '3', '4']\n","\n","hmda19_df2 = hmda19_df2[((hmda19_df2['loan_type'] == '1') | (hmda19_df2['loan_type'] == '2'))\\\n","                      & (hmda19_df2['occupancy_type'] == '1') &\\\n","                        (hmda19_df2['total_units'].isin(one_to_four)) &\\\n","                        (hmda19_df2['loan_purpose'] == '1') &\\\n","                        (hmda19_df2['action_taken'] != '6') &\\\n","                        (hmda19_df2['construction_method'] == '1') &\\\n","                        (hmda19_df2['lien_status'] == '1') &\\\n","                        (hmda19_df2['business_or_commercial_purpose'] != '1')].copy()\n","\n","print('hmda19_df2: ' + str(len(hmda19_df2)))\n","print('hmda19_df2: ' + str(len(hmda19_df2)))"]},{"cell_type":"markdown","source":["## 15-Output"],"metadata":{"id":"k6jP7Ij2Fb-r"}},{"cell_type":"code","source":["hmda19_df2.to_csv(\"output2.csv\", index=False)\n","print(hmda19_df2)"],"metadata":{"id":"o3V76WUWFds9"},"execution_count":null,"outputs":[]}]}